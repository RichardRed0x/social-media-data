#!/usr/bin/env python3

# tsu - time series utility

import os
import csv
import json
from datetime import datetime
from urllib.parse import urlparse, urlunparse
import time

class Config:
    data_dir            = "data"
    errors_filename     = "errors.csv"
    export_filename     = "export.csv"
    profile_filename    = "profile.json"

# Define and catch our own exception to avoid intercepting language and library exceptions.
class TsuError(Exception):
    pass

class ValidationError(TsuError):
    pass

class CommandError(TsuError):
    pass

def parse(entry, int_val=True):
    if len(entry) != 2:
        raise ValidationError("entry must have exactly 2 fields: " + str(entry))
    s1, s2 = entry
    try:
        tsi = int(s1)
    except ValueError as e:
        raise ValidationError("timestamp is not an integer: '{}'".format(s1)) from e
    try:
        dt = datetime.utcfromtimestamp(tsi)
    except Exception as e:
        raise ValidationError("cannot parse datetime from timestamp: '{}'".format(tsi)) from e
    if int_val:
        try:
            val = int(s2)
        except ValueError as e:
            raise ValidationError("value is not an integer: '{}'".format(s2)) from e
    else:
        if len(s2) > 0:
            val = s2
        else:
            raise ValidationError("value is empty")
    return dt, val

STRING_VALUE_FILES = frozenset([Config.errors_filename])

def csv_iter(filename):
    """Generator yielding rows of the csv file."""
    with open(filename, newline="") as f:
        yield from csv.reader(f)

def write_csv(filename, rows):
    # overwrite existing file
    with open(filename, "w", newline="") as f:
        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL, lineterminator="\n")
        writer.writerows(rows)

def validate(path, view=False):
    with open(path, newline='') as csvfile:
        r = csv.reader(csvfile)
        int_values = os.path.basename(path) not in STRING_VALUE_FILES
        prev_dt = datetime.min
        for row in r:
            try:
                dt, val = parse(row, int_values)
                if dt <= prev_dt:
                    raise ValidationError("timestamp '{}' must be greater than '{}'".format(dt, prev_dt))
                prev_dt = dt
                if view:
                    if int_values:
                        print(dt, "{:>6,}".format(val))
                    else:
                        print(dt, val)
            except ValidationError as e:
                print("err {}:{}: {}".format(path, r.line_num, e))

def cmd_view(args):
    path = args.file
    if not os.path.isfile(path):
        raise CommandError("expected a file but got a directory: " + path)
    if not path.endswith(".csv"):
        raise CommandError("expected a csv file but got: " + path)
    validate(args.file, True)

def cmd_validate(args):
    path = args.path
    if os.path.isfile(path):
        # todo: raise ex if not path.endswith(".csv")
        validate(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                if fname.endswith(".csv"):
                    validate(os.path.join(curdir, fname))

def strip_prefix(s, p):
    if s.startswith(p):
        return s[len(p):]
    else:
        return s

def export_append_rows(rows, fpath):
    if not fpath.endswith(".csv"):
        return
    dirname, fname = os.path.split(fpath)
    # metric name is the file name without extension
    metric = os.path.splitext(fname)[0]
    # strip the data directory prefix path component
    plat_acc = strip_prefix(dirname, Config.data_dir + os.sep)
    # platform is the first path component, account is the rest
    platform, account = plat_acc.split(os.sep, maxsplit=1)
    with open(fpath, newline='') as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            ts, val = row
            rows.append((ts, platform, account, metric, val))

def export_csv(path, outname):
    rows = []
    if os.path.isfile(path):
        export_append_rows(rows, path)
    for curdir, dirs, files in os.walk(path):
        for fname in files:
            if fname == Config.errors_filename:
                continue
            export_append_rows(rows, os.path.join(curdir, fname))

    # sort by timestamp, in-place
    rows.sort(key = lambda entry: entry[0])

    # overwrite existing file
    with open(outname, "w", newline="") as outfile:
        writer = csv.writer(outfile, lineterminator="\n")
        writer.writerow(("timestamp", "platform", "account", "metric", "value"))
        writer.writerows(rows)
    print("file saved:", outname)

def cmd_export_csv(args):
    export_csv(args.path, args.output)

def load_json(path):
    with open(path) as f:
        return json.load(f)

def replace_url(url):
    # replace some URLs for easier data point collection
    pu = urlparse(url)
    if pu.netloc == "twitter.com":
        newpu = pu._replace(netloc = "nitter.net")
        newurl = urlunparse(newpu)
        return newurl
    return url

def make_hint(dirpath, default_hint):
    ppath = os.path.join(dirpath, Config.profile_filename)
    hint = ""
    if os.path.exists(ppath):
        pdata = load_json(ppath)
        if "name" in pdata:
            hint += '"' + pdata["name"] + '"'
        if "url" in pdata:
            if hint:
                hint += " "
            hint += replace_url(pdata["url"])

    return hint if hint else default_hint

def optional_input(prompt):
    """Read a string from standard input, canceling on double blank entry.

    Wrap standard input() and return (True, string) on success or (False, None)
    if user cancels.
    """
    try:
        s = input(prompt)
        if s == "":
            s = input("enter blank again to skip or a value to continue: ")
            if s == "":
                return (False, None)
        return (True, s)
    except EOFError:
        print("(got EOF)")
        return (False, None)

def confirmed_input(prompt, confirm_prompt):
    """Read inputs until two subsequent inputs match, canceling on blank input.

    If user cancels input, return what optional_input returned.
    """
    # set up the loop
    ok, prev = optional_input(prompt)
    if not ok:
        return (ok, prev)

    # keep collecting inputs until (a) two inputs match or (b) input is canceled
    while True:
        ok, cur = optional_input(confirm_prompt)
        if (not ok) or (cur == prev):
            return (ok, cur)
        prev = cur

def make_prompt_prefix(path):
    # treat file's parent dir as "account" and filename w/o ext as "metric"
    dpath, fname = os.path.split(path)
    adpath = os.path.abspath(dpath)
    acc = os.path.basename(adpath)
    metric = os.path.splitext(fname)[0]
    return acc + "/" + metric

def entry_file(path):
    if not path.endswith(".csv"):
        raise TsuError("expected a csv file but got: " + path)
    dname, fname = os.path.split(path)

    prompt_prefix = make_prompt_prefix(path)

    hint = make_hint(dname, fname)
    print("{}: capture the value for {}".format(prompt_prefix, hint))

    int_values = fname not in STRING_VALUE_FILES
    rows = list(csv_iter(path)) # read all to get the length
    had_values = len(rows) > 0
    if had_values:
        last_dt, last_val = parse(rows[-1], int_values)
        # extra output for a sanity check
        print("{}: last record is: time {}, value {}".format(prompt_prefix, last_dt, last_val))

    delta = ""
    if int_values:
        while True: # entry loop for int value
            ok, s = confirmed_input("{}: enter integer value: ".format(prompt_prefix),
                                    "{}: confirm integer value: ".format(prompt_prefix))
            if not ok:
                print("{}: skipping".format(prompt_prefix))
                return
            try:
                val = int(s)
                break # entry loop
            except ValueError as e:
                print("{}: expected an integer but got: {}".format(prompt_prefix, s))
        delta = " ({:+})".format(val - last_val) if had_values else ""
    else:
        ok, s = confirmed_input("{}: enter string value: ".format(prompt_prefix),
                                "{}: confirm string value: ".format(prompt_prefix))
        if not ok:
            print("{}: skipping".format(prompt_prefix))
            return
        val = s

    now = int(time.time())
    rows.append((now, val))
    write_csv(path, rows)
    print("{}: saved: time {}, value {}{}".format(prompt_prefix, datetime.utcfromtimestamp(now), val, delta))

def cmd_entry(args):
    """Enter data manually in an interactive session.

    You will be prompted to enter data points one by one for each applicable
    file. After collecting the input value, UTC timestamp will be generated
    and appended to the end of file together with the new value. Make sure your
    system clock is accurate.

    To protect from errors, you will be prompted to enter each value twice.

    To skip entering current value, enter a blank line twice or hit Ctrl-D
    (Ctl-Z+Return on Windows).

    To quit the data entry session, hit Ctrl-C.
    """
    print("Interactive data entry mode. Make sure your system clock is accurate.")
    print("Your system UTC time is:", format(datetime.utcfromtimestamp(int(time.time()))))
    path = args.path
    if os.path.isfile(path):
        if not path.endswith(".csv"):
            raise CommandError("expected a csv file but got: " + path)
        entry_file(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                if fname.endswith(".csv"):
                    entry_file(os.path.join(curdir, fname))

def make_arg_parser():
    import argparse

    parser = argparse.ArgumentParser(description="time series utility")
    subparsers = parser.add_subparsers(dest="command", title="commands")

    validate = subparsers.add_parser(
        "validate", aliases=["val"],
        help="validate time series files")
    validate.add_argument(
        "path", nargs='?',
        default=Config.data_dir,
        help="path to search csv files")
    validate.set_defaults(func=cmd_validate)

    view = subparsers.add_parser(
        "view", aliases=["v"],
        help="view time series file")
    view.add_argument(
        "file",
        help="file to view")
    view.set_defaults(func=cmd_view)

    export = subparsers.add_parser(
        "export",
        help="export data into a single file",
        description=("Export data from arbitrary tree of csv files into a" +
                     " single file (" + Config.export_filename + " by default)," +
                     " overwriting it. " + Config.errors_filename + " files are ignored."))
    export.add_argument(
        "path", nargs='?',
        default=Config.data_dir,
        help="path to search csv files")
    export.add_argument(
        "--output",
        default=Config.export_filename,
        help="file name to save")
    export.set_defaults(func=cmd_export_csv)

    entry = subparsers.add_parser(
        "entry", aliases=["e"],
        help="enter data manually",
        description=cmd_entry.__doc__)
    entry.add_argument(
        "path", nargs='?',
        default=Config.data_dir,
        help="file or directory path to enter data in; if directory, the"
             " program will prompt data entry for each CSV file found in it")
    entry.set_defaults(func=cmd_entry)

    return parser

def main():
    parser = make_arg_parser()
    args = parser.parse_args()

    if args.command:
        try:
            args.func(args)
        except TsuError as e:
            print("error:", e)
        except KeyboardInterrupt:
            print("\naborting")
        except BrokenPipeError:
            # silence error when e.g. piping into `less` and quitting before reading all
            pass
    else:
        parser.print_usage()

if __name__ == "__main__":
    main()
