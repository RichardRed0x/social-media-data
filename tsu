#!/usr/bin/env python3

# tsu - time series utility

import os
import csv
import json
from datetime import datetime, timezone
from itertools import chain
from urllib.parse import urlparse, urlunparse
import time

class Config:
    data_dir            = "data/data"
    export_filename     = "export.csv"
    profile_filename    = "profile.json"
    graph_list_file     = "graph.list"

class Const:
    int_exts            = (".csv", ".tsi")
    str_exts            = (".tss", )

# Define and catch our own exception to avoid intercepting language and library
# exceptions.
class TsuError(Exception):
    pass

class ValidationError(TsuError):
    pass

def parse(entry, valtype):
    if len(entry) != 2:
        raise ValidationError(
            "entry must have exactly 2 fields: " + str(entry))
    s1, s2 = entry
    try:
        tsi = int(s1)
    except ValueError as e:
        raise ValidationError(
            "timestamp is not an integer: '{}'".format(s1)) from e
    try:
        dt = datetime.utcfromtimestamp(tsi)
    except Exception as e:
        raise ValidationError(
            "cannot parse datetime from timestamp: '{}'".format(tsi)) from e
    if valtype == int:
        try:
            val = int(s2)
        except ValueError as e:
            raise ValidationError(
                "value is not an integer: '{}'".format(s2)) from e
    else:
        if len(s2) > 0:
            val = s2
        else:
            raise ValidationError("value is empty")
    return dt, val

def value_type(path):
    ext = os.path.splitext(path)[1]
    if ext in Const.int_exts:
        return int
    elif ext in Const.str_exts:
        return str
    else:
        return None

def csv_iter(filename):
    """Generator yielding rows of the csv file."""
    with open(filename, newline="") as f:
        yield from csv.reader(f)

def write_csv(filename, rows):
    # overwrite existing file
    with open(filename, "w", newline="") as f:
        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL, lineterminator="\n")
        writer.writerows(rows)

def print_entry(dt, val, valtype):
    if valtype == int:
        print(dt, "{:>6,}".format(val))
    else:
        print(dt, val)

def validate(path, view=False):
    valtype = value_type(path)
    prev_dt = datetime.min

    # start counting from 1 to match file line number
    for line_num, row in enumerate(csv_iter(path), start=1):
        try:
            dt, val = parse(row, valtype)
            if dt <= prev_dt:
                raise ValidationError(
                    "timestamp '{}' must be greater than '{}'".format(dt, prev_dt))
            prev_dt = dt
            if view:
                print_entry(dt, val, valtype)
        except ValidationError as e:
            print("err {}:{}: {}".format(path, line_num, e))

def cmd_view(args):
    path = args.file
    if not os.path.isfile(path):
        raise TsuError("path is not a file: " + path)
    # try to handle the file regardless of its type
    validate(args.file, view=True)

def cmd_validate(args):
    path = args.path
    if os.path.isfile(path):
        # try to handle the file regardless of its type
        validate(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                # only validate files of known type
                if value_type(fname) is not None:
                    validate(os.path.join(curdir, fname))

def load_list(path):
    with open(path) as f:
        return [line.rstrip("\n") for line in f]

def strip_prefix(s, p):
    if s.startswith(p):
        return s[len(p):]
    else:
        return s

def load_profile(dirpath):
    ppath = os.path.join(dirpath, Config.profile_filename)
    if os.path.exists(ppath):
        return load_json(ppath)
    else:
        return None

def metric_attrs(path):
    prefix = Config.data_dir + os.sep
    if not path.startswith(prefix):
        # didn't consider this case thoroughly
        return None
    innerpath = strip_prefix(path, prefix)
    parts = innerpath.split(os.sep)
    valid = len(parts) >= 3
    if not valid:
        return None
    # platform is the first path component under Config.data_dir
    # account is 1+ path components under platform, except the last one
    platform, *account, metric_ext = parts
    account_str = "/".join(account)
    # metric name is the file name without extension
    metric = os.path.splitext(metric_ext)[0]
    return platform, account_str, metric

def export_append_rows(rows, fpath, graph):
    attrs = metric_attrs(fpath)
    if not attrs:
        print("WARNING: skipping unexpected file:", fpath)
        return

    platform, account, metric = attrs
    graph_int = int(graph)
    tags = ""
    profile = load_profile(os.path.dirname(fpath))
    if profile and ("tags" in profile):
        tags = " ".join(profile["tags"])
    for ts, val in csv_iter(fpath):
        rows.append((ts, platform, account, metric, val, graph_int, tags))

def export_csv(path, outname, graph_only):
    rows = []
    if os.path.isfile(path):
        # try to handle the file regardless of its type
        export_append_rows(rows, path)
    else:
        graph_paths = []
        if os.path.isfile(Config.graph_list_file):
            graph_paths = load_list(Config.graph_list_file)
            print("loaded {} paths from {}".format(
                len(graph_paths), Config.graph_list_file))
        if graph_only:
            export_paths = graph_paths
            print("exporting {} paths".format(len(export_paths)))
        else:
            print("exporting paths:", path)
            export_paths = [path]
        for ep in export_paths:
            for curdir, dirs, files in os.walk(ep):
                for fname in files:
                    # only export files with int values
                    if value_type(fname) == int:
                        fpath = os.path.join(curdir, fname)
                        # set `graph` column to True if the file is whitelisted
                        graph = any(map(fpath.startswith, graph_paths))
                        export_append_rows(rows, fpath, graph)

    # sort by timestamp, in-place
    rows.sort()
    print("found {} data points".format(len(rows)))

    header = ("timestamp", "platform", "account", "metric", "value", "graph",
              "tags")

    # overwrite existing file
    write_csv(outname, chain([header], rows))
    print("file saved:", outname)

def cmd_export_csv(args):
    export_csv(args.path, args.output, args.graph_only)

def load_json(path):
    with open(path) as f:
        return json.load(f)

def replace_url(url):
    # replace some URLs for easier data point collection
    pu = urlparse(url)
    if pu.netloc == "twitter.com":
        newpu = pu._replace(netloc="nitter.net")
        newurl = urlunparse(newpu)
        return newurl
    return url

def make_hint(dirpath, default_hint):
    profile = load_profile(dirpath)
    hint = ""
    if profile:
        if "name" in profile:
            hint += '"' + profile["name"] + '"'
        if "url" in profile:
            if hint:
                hint += " "
            hint += replace_url(profile["url"])

    return hint if hint else default_hint

class SpecialValue:
    pass

class InputCancel(SpecialValue):
    pass

def optional_input(prompt):
    """Read a string from standard input, cancel on double blank entry.

    Wrap standard input() and return (True, string) on success or
    (False, None) if user cancels.
    """
    try:
        s = input(prompt)
        if s == "":
            s = input("enter blank again to skip or a value to continue: ")
            if s == "":
                return InputCancel()
        return s
    except EOFError:
        print("(got EOF)")
        return InputCancel()

class Command(SpecialValue):
    pass

class TimestampCommand(Command):
    pass

def command_input(prompt):
    while True:
        inp = optional_input(prompt)
        if isinstance(inp, str) and inp.startswith(":"):
            if inp == ":t":
                return TimestampCommand()
            else:
                raise ValueError("unknown command '{}'".format(inp))
        else:
            return inp

def confirmed_input(prompt, confirm_prompt):
    """Read inputs until two subsequent inputs match, cancel on blank input.

    If user cancels input, return what optional_input returned.
    """
    inp = command_input(prompt)
    if isinstance(inp, SpecialValue):
        return inp

    prev = inp
    # keep collecting inputs until (a) two inputs match or (b) input is canceled
    while True:
        cur = optional_input(confirm_prompt)
        if (cur == prev) or isinstance(cur, SpecialValue):
            return cur
        prev = cur

def validated_input(prompt_prefix, typedesc, converter):
    while True:
        try:
            inp = confirmed_input(
                "{}: enter {} value: ".format(prompt_prefix, typedesc),
                "{}: confirm {} value: ".format(prompt_prefix, typedesc))
            if isinstance(inp, SpecialValue):
                return inp
            return converter(inp)
        except ValueError as e:
            print("{}: error: {}".format(prompt_prefix, str(e)))

def int_converter(s):
    try:
        return int(s)
    except ValueError as e:
        raise ValueError("expected an integer but got: " + s)

def parse_date(date_string, format):
    # extend datetime.strptime formats with %s from the `date` program
    if format == "%s":
        return datetime.utcfromtimestamp(int(date_string))
    else:
        return datetime.strptime(date_string, format)

def datetime_converter(s):
    dt = None
    for f in ["%d %b %Y %H:%M:%S", "%Y-%m-%d %H:%M:%S", "%s"]:
        try:
            dt = parse_date(s, f)
            break
        except ValueError:
            pass

    if not dt:
        raise ValueError("unrecognized date value: " + s)

    return dt

def datetime_greater(other):
    def validator(s):
        dt = datetime_converter(s)
        if dt > other:
            return dt
        else:
            raise ValueError("timestamp must be greater than " + str(other))
    return validator

def timestamp_input(prompt_prefix, min_ts):
    while True:
        converter = datetime_greater(min_ts) if min_ts else datetime_converter
        inp = validated_input(prompt_prefix, "timestamp", converter)
        if isinstance(inp, Command):
            print("{}: error: commands are not allowed while entering"
                  " timestamp".format(prompt_prefix))
        else:
            return inp

def identity(x):
    return x

def make_prompt_prefix(path):
    attrs = metric_attrs(path)
    if not attrs:
        print("WARNING: could not determine account/metric for:", path)
        return "n/a"
    _, account, metric = attrs
    return account + "/" + metric

def entry_file(path):
    dirpath, filename = os.path.split(path)

    prompt_prefix = make_prompt_prefix(path)

    hint = make_hint(dirpath, filename)
    print("{}: capture the value for {}".format(prompt_prefix, hint))

    valtype = value_type(filename)
    rows = list(csv_iter(path)) # read all to get the length
    last_dt, last_val = None, None
    if len(rows) > 0:
        last_dt, last_val = parse(rows[-1], valtype)
        # extra output for a sanity check
        print("{}: last record is: time {}, value {}".format(
            prompt_prefix, last_dt, last_val))

    if valtype == int:
        typedesc, converter = "integer", int_converter
    elif valtype == str:
        typedesc, converter = "string", identity
    else:
        raise Exception("unexpected value type: " + str(valtype))

    dt_custom = None
    while True: # main entry loop
        inp = validated_input(prompt_prefix, typedesc, converter)
        dt = dt_custom if dt_custom else datetime.utcnow().replace(microsecond=0)
        if isinstance(inp, InputCancel):
            print("{}: skipping".format(prompt_prefix))
            return
        elif isinstance(inp, TimestampCommand):
            dt_inp = timestamp_input(prompt_prefix, last_dt)
            if isinstance(dt_inp, datetime):
                print("{}: using timestamp {} for current metric only".format(
                      prompt_prefix, dt_inp))
                dt_custom = dt_inp
            elif isinstance(dt_inp, InputCancel):
                print("{}: timestamp entry canceled".format(prompt_prefix))
        elif isinstance(inp, SpecialValue):
            raise Exception("unexpected SpecialValue: " + str(inp))
        else:
            val = inp
            break # main entry loop

    if valtype == int and last_val:
        delta = " ({:+})".format(val - last_val)
    else:
        delta = ""

    ts = int(dt.replace(tzinfo=timezone.utc).timestamp())
    rows.append((ts, val))
    write_csv(path, rows)
    print("{}: saved: time {}, value {}{}".format(prompt_prefix, dt, val, delta))

def cmd_entry(args):
    """Enter data manually in an interactive session.

    You will be prompted to enter data points one by one for each
    applicable file. After collecting the input value, UTC timestamp
    will be generated and appended to the end of file together with the
    new value. Make sure your system clock is accurate.

    To protect from errors, you will be prompted to enter each value
    twice.

    To skip entering current value, enter a blank line twice or hit
    Ctrl-D (Ctl-Z+Return on Windows).

    To enter the timestamp manually, enter ':t' instead of the value.

    To quit the data entry session, hit Ctrl-C.
    """
    print("Interactive data entry mode. Make sure your system clock is accurate.")
    print("Your system UTC time is:",
          format(datetime.utcfromtimestamp(int(time.time()))))
    path = args.path
    if os.path.isfile(path):
        # try to handle the file regardless of its type
        entry_file(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                # only prompt entry for int values
                if value_type(fname) == int:
                    entry_file(os.path.join(curdir, fname))

def make_arg_parser():
    import argparse

    parser = argparse.ArgumentParser(
        description=("time series utility. The following file types are"
                     "supported: " + ", ".join(Const.int_exts + Const.str_exts)))
    subparsers = parser.add_subparsers(dest="command", title="commands")

    validate = subparsers.add_parser(
        "validate", aliases=["val"],
        help="validate time series files")
    validate.add_argument(
        "path", nargs="?",
        default=Config.data_dir,
        help="path to search time series files")
    validate.set_defaults(func=cmd_validate)

    view = subparsers.add_parser(
        "view", aliases=["v"],
        help="view time series file")
    view.add_argument(
        "file",
        help="file to view")
    view.set_defaults(func=cmd_view)

    export = subparsers.add_parser(
        "export",
        help="export data into a single file",
        description=("Export data from arbitrary tree of time series files"
                     " into a single file (" + Config.export_filename +
                     " by default), overwriting it."))
    export.add_argument(
        "path", nargs="?",
        default=Config.data_dir,
        help="path to search time series files")
    export.add_argument(
        "-g", "--graph-only",
        action="store_true",
        help="export only paths listed in " + Config.graph_list_file)
    export.add_argument(
        "--output",
        default=Config.export_filename,
        help="file name to save")
    export.set_defaults(func=cmd_export_csv)

    entry = subparsers.add_parser(
        "entry", aliases=["e"],
        help="enter data manually",
        description=cmd_entry.__doc__)
    entry.add_argument(
        "path", nargs="?",
        default=Config.data_dir,
        help="file or directory path to enter data in; if directory, the"
             " program will prompt data entry for each time sieries file found"
             " in it")
    entry.set_defaults(func=cmd_entry)

    return parser

def main():
    parser = make_arg_parser()
    args = parser.parse_args()

    if args.command:
        try:
            args.func(args)
        except TsuError as e:
            print("error:", e)
        except KeyboardInterrupt:
            print("\naborting")
        except BrokenPipeError:
            # silence error when e.g. piping into `less` and quitting before
            # reading all
            pass
    else:
        parser.print_usage()

if __name__ == "__main__":
    main()
