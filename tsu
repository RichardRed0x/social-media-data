#!/usr/bin/env python3

# tsu - time series utility

import os
import csv
from datetime import datetime
import time

class Config:
    data_dir            = "data"
    errors_filename     = "errors.csv"
    export_filename     = "export.csv"
    profile_filename    = "profile.yml"

# Define and catch our own exception to avoid intercepting language and library exceptions.
class TsuError(Exception):
    pass

class ValidationError(TsuError):
    pass

class CommandError(TsuError):
    pass

def parse(entry, int_val=True):
    if len(entry) != 2:
        raise ValidationError("entry must have exactly 2 fields: " + str(entry))
    s1, s2 = entry
    try:
        tsi = int(s1)
    except ValueError as e:
        raise ValidationError("timestamp is not an integer: '{}'".format(s1)) from e
    try:
        dt = datetime.utcfromtimestamp(tsi)
    except Exception as e:
        raise ValidationError("cannot parse datetime from timestamp: '{}'".format(tsi)) from e
    if int_val:
        try:
            val = int(s2)
        except ValueError as e:
            raise ValidationError("value is not an integer: '{}'".format(s2)) from e
    else:
        if len(s2) > 0:
            val = s2
        else:
            raise ValidationError("value is empty")
    return dt, val

STRING_VALUE_FILES = frozenset([Config.errors_filename])

def csv_iter(filename):
    """Generator yielding rows of the csv file."""
    with open(filename, newline="") as f:
        yield from csv.reader(f)

def write_csv(filename, rows):
    # overwrite existing file
    with open(filename, "w", newline="") as f:
        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL, lineterminator="\n")
        writer.writerows(rows)

def validate(path, view=False):
    with open(path, newline='') as csvfile:
        r = csv.reader(csvfile)
        int_values = os.path.basename(path) not in STRING_VALUE_FILES
        prev_dt = datetime.min
        for row in r:
            try:
                dt, val = parse(row, int_values)
                if dt <= prev_dt:
                    raise ValidationError("timestamp '{}' must be greater than '{}'".format(dt, prev_dt))
                prev_dt = dt
                if view:
                    if int_values:
                        print(dt, "{:>6,}".format(val))
                    else:
                        print(dt, val)
            except ValidationError as e:
                print("err {}:{}: {}".format(path, r.line_num, e))

def cmd_view(args):
    path = args.file
    if not os.path.isfile(path):
        raise CommandError("expected a file but got a directory: " + path)
    if not path.endswith(".csv"):
        raise CommandError("expected a csv file but got: " + path)
    validate(args.file, True)

def cmd_validate(args):
    path = args.path
    if os.path.isfile(path):
        # todo: raise ex if not path.endswith(".csv")
        validate(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                if fname.endswith(".csv"):
                    validate(os.path.join(curdir, fname))

def strip_prefix(s, p):
    if s.startswith(p):
        return s[len(p):]
    else:
        return s

def export_append_rows(rows, fpath):
    if not fpath.endswith(".csv"):
        return
    dirname, fname = os.path.split(fpath)
    # metric name is the file name without extension
    metric = os.path.splitext(fname)[0]
    # strip the data directory prefix path component
    plat_acc = strip_prefix(dirname, Config.data_dir + os.sep)
    # platform is the first path component, account is the rest
    platform, account = plat_acc.split(os.sep, maxsplit=1)
    with open(fpath, newline='') as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            ts, val = row
            rows.append((ts, platform, account, metric, val))

def export_csv(path, outname):
    rows = []
    if os.path.isfile(path):
        export_append_rows(rows, path)
    for curdir, dirs, files in os.walk(path):
        for fname in files:
            if fname == Config.errors_filename:
                continue
            export_append_rows(rows, os.path.join(curdir, fname))

    # sort by timestamp, in-place
    rows.sort(key = lambda entry: entry[0])

    # overwrite existing file
    with open(outname, "w", newline="") as outfile:
        writer = csv.writer(outfile, lineterminator="\n")
        writer.writerow(("timestamp", "platform", "account", "metric", "value"))
        writer.writerows(rows)
    print("file saved:", outname)

def cmd_export_csv(args):
    export_csv(args.path, args.output)

def get_profile_url(path):
    # this small ad-hoc YAML value extractor allows to avoid adding YAML library dependency
    # todo: migrate to JSON and get rid of this
    with open(path) as f:
        for line in f:
            if line.startswith("url: "):
                return line.rstrip('\n').replace("url: ", "", 1)

def make_hint(dirpath, default_hint):
    profile_path = os.path.join(dirpath, Config.profile_filename)
    if os.path.exists(profile_path):
        return get_profile_url(profile_path)
    else:
        return default_hint

def optional_input(prompt):
    """Read a string from standard input, cancelling on double blank entry.

    Wrap standard input() and return (True, string) on success or (False, None)
    if user cancels.
    """
    s = input(prompt)
    if s == "":
        s = input("enter blank again to skip or a value to continue: ")
        if s == "":
            return (False, None)
    return (True, s)

def entry_file(path):
    if not path.endswith(".csv"):
        raise TsuError("expected a csv file but got: " + path)
    dname, fname = os.path.split(path)
    int_values = fname not in STRING_VALUE_FILES
    rows = list(csv_iter(path)) # read all to get the length
    had_values = len(rows) > 0
    if had_values:
        last_dt, last_val = parse(rows[-1], int_values)
        # extra output for a sanity check
        print("{}: last record is: time {}, value {}".format(fname, last_dt, last_val))
    hint = make_hint(dname, fname)
    print("{}: now capture the value from {}".format(fname, hint))
    if int_values:
        while True: # entry loop for int value
            ok, s = optional_input("{}: enter integer value: ".format(fname))
            if not ok:
                print("{}: skipping".format(fname))
                return
            try:
                val = int(s)
                break # entry loop
            except ValueError as e:
                print("{}: expected an integer but got: {}".format(fname, s))
    else:
        ok, s = optional_input("{}: enter string value: ".format(fname))
        if not ok:
            print("{}: skipping".format(fname))
            return
        val = s

    now = int(time.time())
    rows.append((now, val))
    write_csv(path, rows)
    delta = " ({:+})".format(val - last_val) if had_values else ""
    print("{}: appended: time {}, value {}{}".format(fname, datetime.utcfromtimestamp(now), val, delta))

def cmd_entry(args):
    print("Interactive data entry mode. Make sure your system clock is accurate.")
    print("Your system UTC time is:", format(datetime.utcfromtimestamp(int(time.time()))))
    path = args.path
    if os.path.isfile(path):
        if not path.endswith(".csv"):
            raise CommandError("expected a csv file but got: " + path)
        entry_file(path)
    elif os.path.isdir(path):
        for curdir, dirs, files in os.walk(path):
            for fname in files:
                if fname.endswith(".csv"):
                    entry_file(os.path.join(curdir, fname))

def make_arg_parser():
    import argparse
    parser = argparse.ArgumentParser(description="time series utility")
    subparsers = parser.add_subparsers(dest="command", title="commands")

    parser_validate = subparsers.add_parser("validate", aliases=["val"], help="validate time series files")
    parser_validate.add_argument("path", nargs='?', default=Config.data_dir, help="path to search csv files")
    parser_validate.set_defaults(func=cmd_validate)

    parser_view = subparsers.add_parser("view", aliases=["v"], help="view time series file")
    parser_view.add_argument("file", help="file to view")
    parser_view.set_defaults(func=cmd_view)

    parser_export = subparsers.add_parser("export", help="export data from arbitrary tree of csv files into a single file (" + Config.export_filename + " by default), overwriting it; " + Config.errors_filename + " files are ignored")
    parser_export.add_argument("path", nargs='?', default=Config.data_dir, help="path to search csv files")
    parser_export.add_argument("--output", default=Config.export_filename, help="file name to save")
    parser_export.set_defaults(func=cmd_export_csv)

    parser_entry = subparsers.add_parser("entry", aliases=["e"], help="enter data manually")
    parser_entry.add_argument("path", nargs='?', default=Config.data_dir, help="file or directory path to enter data in; if directory, the program will prompt data entry for each CSV file found in it")
    parser_entry.set_defaults(func=cmd_entry)

    return parser

def main():
    parser = make_arg_parser()
    args = parser.parse_args()

    if args.command:
        try:
            args.func(args)
        except TsuError as e:
            print("error:", e)
        except KeyboardInterrupt:
            print("\naborting")
        except BrokenPipeError:
            # silence error when e.g. piping into `less` and quitting before reading all
            pass
    else:
        parser.print_usage()

if __name__ == "__main__":
    main()
